#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¬¸ì„œ í†µí•© ë„êµ¬
ê°™ì€ ì£¼ì œì˜ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ í¬ê´„ì ì¸ ê°€ì´ë“œë¡œ í†µí•©í•©ë‹ˆë‹¤.
"""

import os
import sys
import shutil
from pathlib import Path
from datetime import datetime

# Windows ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í†µí•© ê·œì¹™ ì •ì˜
CONSOLIDATION_GROUPS = {
    'assets': {
        'output': 'ASSETS_COMPLETE_GUIDE.md',
        'destination': 'docs/assets/',
        'sources': [
            ('docs/ASSETS.md', 'ì „ì²´ ì—ì…‹ ê°œìš”'),
            ('docs/CHAD_ASSET_CREATION.md', 'Chad ìºë¦­í„° ìƒì„±'),
            ('docs/ASSET_CREATION_GUIDE.md', 'í‘¸ì‹œì—… í¼ ê°€ì´ë“œ'),
            ('docs/APP_STORE_IMAGES_GUIDE.md', 'ì•± ìŠ¤í† ì–´ ì´ë¯¸ì§€'),
        ],
        'description': 'ëª¨ë“  ì—ì…‹ ì œìž‘ ê°€ì´ë“œë¥¼ í•˜ë‚˜ë¡œ í†µí•©'
    },
    'midjourney': {
        'output': 'MIDJOURNEY_COMPLETE_GUIDE.md',
        'destination': 'docs/assets/',
        'sources': [
            ('docs/MIDJOURNEY_PROMPTS.md', 'MidJourney ìƒì„¸ ê°€ì´ë“œ'),
            ('docs/MIDJOURNEY_READY_PROMPTS.txt', 'ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸'),
        ],
        'description': 'MidJourney ê°€ì´ë“œ + í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ë¡œ'
    },
    'marketing': {
        'output': 'MARKETING_GUIDE.md',
        'destination': 'docs/deployment/',
        'sources': [
            ('docs/ASO_KEYWORDS.md', 'ASO í‚¤ì›Œë“œ ì „ëžµ'),
            ('docs/VIDEO_PRODUCTION_GUIDE.md', 'ìš´ë™ ë¹„ë””ì˜¤ ì œìž‘'),
        ],
        'description': 'ë§ˆì¼€íŒ… ê´€ë ¨ ê°€ì´ë“œ í†µí•©'
    }
}


def read_file(filepath):
    """íŒŒì¼ ë‚´ìš© ì½ê¸°"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"  âš ï¸  ì½ê¸° ì‹¤íŒ¨: {filepath} - {e}")
        return None


def create_consolidated_doc(group_name, config):
    """í†µí•© ë¬¸ì„œ ìƒì„±"""
    print(f"\n{'='*60}")
    print(f"ðŸ“„ {config['output']} ìƒì„± ì¤‘...")
    print(f"{'='*60}")

    # í—¤ë” ìƒì„±
    title = config['output'].replace('_', ' ').replace('.md', '')
    content = f"""# {title}

> í†µí•© ê°€ì´ë“œ - {config['description']}

**ìƒì„±ì¼**: {datetime.now().strftime('%Y-%m-%d')}
**í¬í•¨ ë¬¸ì„œ**: {len(config['sources'])}ê°œ

---

## ðŸ“‹ ëª©ì°¨

"""

    # ëª©ì°¨ ìƒì„±
    for idx, (source_path, description) in enumerate(config['sources'], 1):
        section_id = description.lower().replace(' ', '-').replace('/', '-')
        content += f"{idx}. [{description}](#{section_id})\n"

    content += "\n---\n\n"

    # ê° ì†ŒìŠ¤ ë¬¸ì„œ ë‚´ìš© ì¶”ê°€
    for idx, (source_path, description) in enumerate(config['sources'], 1):
        print(f"  [{idx}/{len(config['sources'])}] {description}...")

        source_content = read_file(source_path)
        if not source_content:
            content += f"\n\n## {idx}. {description}\n\nâŒ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{source_path}`\n\n"
            continue

        # ì„¹ì…˜ ì¶”ê°€
        content += f"\n\n## {idx}. {description}\n\n"
        content += f"> **ì›ë³¸ ë¬¸ì„œ**: `{source_path}`\n\n"
        content += "---\n\n"

        # ì›ë³¸ ë‚´ìš©ì˜ í—¤ë” ë ˆë²¨ ì¡°ì • (# â†’ ###)
        lines = source_content.split('\n')
        adjusted_lines = []

        for line in lines:
            # ë§¨ ì²« ì¤„ ì œëª©ì€ ê±´ë„ˆë›°ê¸°
            if line.startswith('# ') and len(adjusted_lines) == 0:
                continue
            # í—¤ë” ë ˆë²¨ ì¡°ì •
            elif line.startswith('# '):
                adjusted_lines.append('###' + line[1:])
            elif line.startswith('## '):
                adjusted_lines.append('####' + line[2:])
            elif line.startswith('### '):
                adjusted_lines.append('#####' + line[3:])
            else:
                adjusted_lines.append(line)

        content += '\n'.join(adjusted_lines)
        content += "\n\n---\n\n"

    # í‘¸í„° ì¶”ê°€
    content += f"""
## ðŸ”— ê´€ë ¨ ë¬¸ì„œ

"""

    for source_path, description in config['sources']:
        content += f"- [{description}]({source_path})\n"

    content += f"""

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
**ê´€ë¦¬**: ìžë™ ìƒì„± (tools/consolidate_docs.py)
"""

    # íŒŒì¼ ì €ìž¥
    output_path = Path(config['destination']) / config['output']
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print(f"  âœ… ìƒì„± ì™„ë£Œ: {output_path}")
    print(f"  ðŸ“Š í¬ê¸°: {len(content):,} bytes")

    return output_path


def archive_original_files(config):
    """ì›ë³¸ íŒŒì¼ë“¤ì„ archiveë¡œ ì´ë™"""
    archived = []

    for source_path, description in config['sources']:
        if not Path(source_path).exists():
            continue

        # archive ê²½ë¡œ ìƒì„±
        archive_path = Path('docs/archive') / Path(source_path).name

        try:
            shutil.move(source_path, archive_path)
            archived.append((source_path, archive_path))
            print(f"  ðŸ“¦ {Path(source_path).name} â†’ archive/")
        except Exception as e:
            print(f"  âš ï¸  ì´ë™ ì‹¤íŒ¨: {source_path} - {e}")

    return archived


def preview_consolidation():
    """í†µí•© ê³„íš ë¯¸ë¦¬ë³´ê¸°"""
    print("\n" + "="*60)
    print("ðŸ“„ ë¬¸ì„œ í†µí•© ê³„íš")
    print("="*60)

    total_sources = sum(len(config['sources']) for config in CONSOLIDATION_GROUPS.values())

    print(f"\nðŸ“Š í†µê³„:")
    print(f"  - í†µí•© ê·¸ë£¹: {len(CONSOLIDATION_GROUPS)}ê°œ")
    print(f"  - ì›ë³¸ ë¬¸ì„œ: {total_sources}ê°œ")
    print(f"  - ìƒì„± ë¬¸ì„œ: {len(CONSOLIDATION_GROUPS)}ê°œ")
    print(f"  - ê°ì†Œ: {total_sources - len(CONSOLIDATION_GROUPS)}ê°œ")

    for group_name, config in CONSOLIDATION_GROUPS.items():
        print(f"\n{'-'*60}")
        print(f"ðŸ“ ê·¸ë£¹: {group_name}")
        print(f"  ì¶œë ¥: {config['output']}")
        print(f"  ìœ„ì¹˜: {config['destination']}")
        print(f"  ì„¤ëª…: {config['description']}")
        print(f"  í†µí•©í•  ë¬¸ì„œ ({len(config['sources'])}ê°œ):")

        for source_path, description in config['sources']:
            exists = "âœ…" if Path(source_path).exists() else "âŒ"
            print(f"    {exists} {description} ({source_path})")

    print("\n" + "="*60)
    print(f"\nìµœì¢… ê²°ê³¼:")
    print(f"  {total_sources}ê°œ ë¬¸ì„œ â†’ {len(CONSOLIDATION_GROUPS)}ê°œ í†µí•© ê°€ì´ë“œ")
    print(f"  ì›ë³¸ íŒŒì¼ë“¤ì€ docs/archive/ë¡œ ì´ë™ë©ë‹ˆë‹¤")
    print("="*60)


def execute_consolidation():
    """í†µí•© ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ðŸš€ ë¬¸ì„œ í†µí•© ì‹¤í–‰ ì¤‘...")
    print("="*60)

    created_files = []
    archived_files = []

    # ê° ê·¸ë£¹ë³„ë¡œ í†µí•©
    for group_name, config in CONSOLIDATION_GROUPS.items():
        print(f"\n[{group_name.upper()}] ê·¸ë£¹ ì²˜ë¦¬ ì¤‘...")

        # í†µí•© ë¬¸ì„œ ìƒì„±
        output_path = create_consolidated_doc(group_name, config)
        created_files.append(output_path)

        # ì›ë³¸ íŒŒì¼ archiveë¡œ ì´ë™
        print(f"\n  ì›ë³¸ íŒŒì¼ ì •ë¦¬ ì¤‘...")
        archived = archive_original_files(config)
        archived_files.extend(archived)

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("âœ… ë¬¸ì„œ í†µí•© ì™„ë£Œ!")
    print("="*60)

    print(f"\nðŸ“ ìƒì„±ëœ í†µí•© ë¬¸ì„œ ({len(created_files)}ê°œ):")
    for file_path in created_files:
        print(f"  âœ… {file_path}")

    print(f"\nðŸ“¦ Archiveë¡œ ì´ë™ëœ íŒŒì¼ ({len(archived_files)}ê°œ):")
    for source, dest in archived_files:
        print(f"  ðŸ“¦ {Path(source).name}")

    print(f"\nìƒˆ ë¬¸ì„œ êµ¬ì¡°:")
    print(f"  docs/")
    print(f"  â”œâ”€â”€ assets/")
    print(f"  â”‚   â”œâ”€â”€ ASSETS_COMPLETE_GUIDE.md")
    print(f"  â”‚   â””â”€â”€ MIDJOURNEY_COMPLETE_GUIDE.md")
    print(f"  â”œâ”€â”€ deployment/")
    print(f"  â”‚   â””â”€â”€ MARKETING_GUIDE.md")
    print(f"  â””â”€â”€ archive/")
    print(f"      â””â”€â”€ {len(archived_files)}ê°œ ì›ë³¸ ë¬¸ì„œ")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == '--execute':
        execute_consolidation()
    else:
        preview_consolidation()
        print(f"\nì‹¤í–‰í•˜ë ¤ë©´: python {sys.argv[0]} --execute")


if __name__ == '__main__':
    main()
